{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (20 pts)\n",
    "\n",
    "In the case when you sample a sufficiently large number of normally distributed random variables $\\{\\eta_i\\}_1^N$ with a given covariation function $k$ (using, for example, Cholesky decomposition of the covariance matrix or a square root of it), it may turn out that a smaller number of i.i.d random variables $\\{\\xi_i\\}_1^m$ is sufficient to achieve a given accuracy. (Draw an analogy with the low-rank decomposition of the matrix, and the truncated KL expansion.)\n",
    "\n",
    "Let the covariance of the GP $f$ with zero mean reads $$k(x,y)=\\exp\\left(-|x-y|^2/(2\\ell^2)\\right)$$ with $\\ell=0.7$, and let we have $N=51$ points $\\{x_i\\}_{i=1}^{51}$\n",
    "uniformly covering the interval $[-5,\\,5]$ (so $x_i=-5+(i-1)/5)$. Consider a vector of r.v. $\\eta$ with components $\\eta_i=f(x_i)$, so it has a covariance matrix $K=k(\\{x_i\\},\\{x_i\\})$.\n",
    " - **(10 pts)** Find a linear combination $\\theta=\\mathbf v\\cdot\\mathbf \\eta$ of r.v.  which is \"almost\" not random ($\\sigma(\\theta)\\approx0$, where $\\sigma$ is standard deviation). Here $\\mathbf v\\in\\mathbb R^N$ is a deterministic vector of the unit length, $\\|\\mathbf v\\|_2=1$. Try to find the best vector $\\mathbf v$ in this sense.\n",
    " - **(10 pts)** Write a Python function that samples this $51$ r.v.  on the base of $m=10$ i.i.d. r.v. $\\{\\xi_i\\}_{i=1}^m$ with the least possible error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "θ = [ 1.8496188382 -2.3121479511  0.6349899156  2.4425555418  0.6682798465 -2.8134947731  1.5934918463  3.3011856958\n",
      "  8.2929929663 -0.1606794129]...\n",
      "\n",
      "2.8751 ?<? 2e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial as SP\n",
    "\n",
    "N = 51\n",
    "ell = 0.7\n",
    "x = np.linspace(-5, 5, N)\n",
    "\n",
    "\n",
    "def kernel(a, b):\n",
    "    sqdist = SP.distance.cdist(a, b, 'sqeuclidean')\n",
    "    return np.exp(-.5 * sqdist/(ell**2))\n",
    "\n",
    "\n",
    "def sample_K(K, N_samples=int(1e5)):\n",
    "    N = len(K)\n",
    "    L = np.linalg.cholesky(K + 1e-12*np.eye(N))\n",
    "    xi = np.random.normal(size=(N, N_samples))\n",
    "    eta = L.dot(xi)\n",
    "    return eta\n",
    "\n",
    "\n",
    "K = kernel(x[:, None], x[:, None])\n",
    "np.random.seed(42)\n",
    "smpl = sample_K(K)\n",
    "\n",
    "# Problem 1a\n",
    "# !!! Find this vector !!!\n",
    "v = np.ones(N)\n",
    "v /= np.linalg.norm(v, 2)\n",
    "\n",
    "print(\"θ = {}...\".format(v.dot(smpl)[:10]))\n",
    "std = np.std(v.dot(smpl))\n",
    "threshold = 2e-06\n",
    "print(\"\\n{0:.5g} {2} {1}\".format(std, threshold, '<' if std < threshold else '?<?') )  # must be almost zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008134245251439354\n"
     ]
    }
   ],
   "source": [
    "# Problem 1b\n",
    "# Write this function\n",
    "def sample_K_m(K, m, N_samples=int(1e5)):\n",
    "    xi = np.random.normal(size=(m, N_samples))  # Only m, not N!\n",
    "    # ...\n",
    "    # ...\n",
    "    # return eta\n",
    "\n",
    "\n",
    "m = 10\n",
    "#smpl = sample_K_m(K, m)\n",
    "\n",
    "\n",
    "def empirical_cov(smpl):\n",
    "    N, N_samples = smpl.shape\n",
    "    res = np.zeros((N, N))\n",
    "    for i in smpl.T:\n",
    "        res += np.multiply.outer(i, i)\n",
    "\n",
    "    return res/(N_samples-1)\n",
    "\n",
    "\n",
    "K_emp = empirical_cov(smpl)\n",
    "delta = np.max(np.abs((K - K_emp)))\n",
    "print(delta)  # must be small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 (60 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Consider an stochastic PDE$\\def\\intrvl{[-2,\\,1]}$\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{aligned}\n",
    "\\frac\\partial{\\partial t}u(x,t,\\xi)&=\n",
    "\\frac\\partial{\\partial x}\\left(k(x,\\xi)\\frac\\partial{\\partial x}u(t,x,\\xi)\\right)+1,&x&\\in\\intrvl,\\;\\;t\\in[0,\\,T],\\\\\n",
    "u(t,-2,\\xi)&=u(t,1,\\xi)=0,&t&\\in[0,\\,T],\\\\\n",
    "u(0,x,\\xi)&=0,&x&\\in\\intrvl\n",
    "\\end{aligned}\n",
    "\\right..\n",
    "$$\n",
    "Here $k(x,\\xi)$ is a random function with the mean $\\mu=15$ and\n",
    "the covariance function \n",
    "$$\n",
    "\\text{cov}\\bigl(k(x,\\xi),\\,k(y,\\xi)\\bigr)=\\frac32\\exp\\bigl(-0.3\\left|x-y\\right|\\bigr).\n",
    "$$\n",
    "\n",
    "- **(5 pts)** Use Karhunen–Loève expansion to model the field $k$.\n",
    "- **(30 pts)** Use gPC to represent the unknown value $u$,\n",
    "solve the corresponding equation on the coefficients of the expansion and find the mean\n",
    "and the variance of the solution $u$ at time $t=1$ as functions of $x$.\n",
    "- **(15 pts)** Additionally, use Monte-Carlo method to model this mean and variance at the same time $t=1$.\n",
    "- **(10 pts)** Compare  the results by plotting them on a single chart, find the optimal approximation parameters (the number of terms in the KL decomposition, the maximum degree of the polynomial in the gPC decomposition).\n",
    "\n",
    "*Hint: you can use the analytical expressions for eigenfunction and eigenvalues and the code from Lecture 6 and use the code for multivariate gPC approximation form Lecture 7.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
